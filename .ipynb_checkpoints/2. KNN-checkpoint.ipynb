{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30e5d8bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-55e82809798a>:34: RuntimeWarning: divide by zero encountered in divide\n",
      "  weights = 1.0 / np.array(distances)  # Inverse weighting\n",
      "<ipython-input-1-55e82809798a>:35: RuntimeWarning: invalid value encountered in multiply\n",
      "  vote_counts = Counter(neighbors_labels * weights)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets  # For a sample dataset\n",
    "from collections import Counter\n",
    "\n",
    "class KNN:\n",
    "    def __init__(self, k=3, distance_metric='euclidean', weighted=False):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weighted = weighted\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def _calculate_distance(self, x1, x2):\n",
    "        if self.distance_metric == 'euclidean':\n",
    "            return np.linalg.norm(x1 - x2)\n",
    "        elif self.distance_metric == 'manhattan':\n",
    "            return np.sum(np.abs(x1 - x2))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid distance metric\")\n",
    "\n",
    "    def _get_neighbors(self, x):\n",
    "        distances = [self._calculate_distance(x, x_train) for x_train in self.X_train]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        return sorted_indices[:self.k]\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        neighbors_idx = self._get_neighbors(x)\n",
    "        neighbors_labels = self.y_train[neighbors_idx]\n",
    "\n",
    "        if self.weighted:\n",
    "            distances = [self._calculate_distance(x, self.X_train[idx]) for idx in neighbors_idx]\n",
    "            weights = 1.0 / np.array(distances)  # Inverse weighting\n",
    "            vote_counts = Counter(neighbors_labels * weights)  \n",
    "        else:\n",
    "            vote_counts = Counter(neighbors_labels)  \n",
    "\n",
    "        return vote_counts.most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict_single(x) for x in X]\n",
    "\n",
    "    def _accuracy(self, y_true, y_pred):\n",
    "        return np.sum(y_true == y_pred) / len(y_true)\n",
    "        \n",
    "    # ... Other potential custom metrics like precision, recall, etc.\n",
    "\n",
    "# **Sample Usage**\n",
    "if __name__ == '__main__':\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "\n",
    "\n",
    "    knn = KNN(k=5, distance_metric='euclidean', weighted=True)\n",
    "    knn.fit(X, y)\n",
    "\n",
    "    y_pred = knn.predict(X) \n",
    "    accuracy = knn._accuracy(y, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d9b117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDNode:\n",
    "    def __init__(self, point, label, left=None, right=None, axis=0):\n",
    "        self.point = point\n",
    "        self.label = label\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.axis = axis\n",
    "\n",
    "class KDTree:\n",
    "    def __init__(self, points, labels):\n",
    "        self.root = self.build_tree(points, labels)\n",
    "    \n",
    "    def build_tree(self, points, labels, depth=0):\n",
    "        if len(points) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Select axis based on depth so that axis cycles over all valid values\n",
    "        axis = depth % len(points[0])\n",
    "        \n",
    "        # Sort point list and choose median as pivot element\n",
    "        sorted_points = sorted(zip(points, labels), key=lambda x: x[0][axis])\n",
    "        median = len(sorted_points) // 2\n",
    "        \n",
    "        # Create node and construct subtrees\n",
    "        return KDNode(\n",
    "            point=sorted_points[median][0],\n",
    "            label=sorted_points[median][1],\n",
    "            left=self.build_tree([x[0] for x in sorted_points[:median]], [x[1] for x in sorted_points[:median]], depth + 1),\n",
    "            right=self.build_tree([x[0] for x in sorted_points[median+1:]], [x[1] for x in sorted_points[median+1:]], depth + 1),\n",
    "            axis=axis\n",
    "        )\n",
    "\n",
    "    def nearest(self, point, k=1):\n",
    "        best = []\n",
    "        self._search_tree(self.root, point, k, best)\n",
    "        return sorted(best, key=lambda x: x[0])[:k]\n",
    "    \n",
    "    def _search_tree(self, node, point, k, best):\n",
    "        if node is None:\n",
    "            return\n",
    "        \n",
    "        # Compute distance from point to current node\n",
    "        dist = euclidean_distance(point, node.point)\n",
    "        \n",
    "        if len(best) < k or dist < best[0][0]:\n",
    "            best.append((dist, node.label))\n",
    "            best.sort(reverse=True)\n",
    "            if len(best) > k:\n",
    "                best.pop(0)\n",
    "        \n",
    "        # Check which subtree to search\n",
    "        if point[node.axis] < node.point[node.axis]:\n",
    "            self._search_tree(node.left, point, k, best)\n",
    "            if len(best) < k or abs(point[node.axis] - node.point[node.axis]) < best[0][0]:\n",
    "                self._search_tree(node.right, point, k, best)\n",
    "        else:\n",
    "            self._search_tree(node.right, point, k, best)\n",
    "            if len(best) < k or abs(point[node.axis] - node.point[node.axis]) < best[0][0]:\n",
    "                self._search_tree(node.left, point, k, best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f12c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((np.array(a) - np.array(b)) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "005475ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classify(kdtree, point, k=3):\n",
    "    neighbors = kdtree.nearest(point, k)\n",
    "    # Perform majority vote\n",
    "    votes = {}\n",
    "    for _, label in neighbors:\n",
    "        votes[label] = votes.get(label, 0) + 1\n",
    "    return max(votes, key=votes.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3889b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, labels):\n",
    "    matrix = np.zeros((len(labels), len(labels)), dtype=int)\n",
    "    label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        matrix[label_to_index[true]][label_to_index[pred]] += 1\n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784620a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    return (data - np.mean(data, axis=0)) / np.std(data, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58085cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      " [[ 7  0  0]\n",
      " [ 0 12  0]\n",
      " [ 0  1 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets  # Only for dataset loading\n",
    "\n",
    "def load_and_split_data(test_ratio=0.2):\n",
    "    iris = datasets.load_iris()\n",
    "    data = normalize(iris.data)\n",
    "    labels = iris.target\n",
    "    indices = np.arange(len(data))\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(len(data) * (1 - test_ratio))\n",
    "    return data[indices[:split]], labels[indices[:split]], data[indices[split:]], labels[indices[split:]]\n",
    "\n",
    "train_data, train_labels, test_data, test_labels = load_and_split_data()\n",
    "\n",
    "# Build KD-Tree with training data\n",
    "kdtree = KDTree(train_data, train_labels)\n",
    "\n",
    "# Test the model\n",
    "predictions = [knn_classify(kdtree, point, k=3) for point in test_data]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy(test_labels, predictions))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(test_labels, predictions, labels=np.unique(test_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc58109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
