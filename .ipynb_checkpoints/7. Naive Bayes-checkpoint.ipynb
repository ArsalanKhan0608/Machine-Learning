{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b66bff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.priors = None\n",
    "        self.feature_likelihoods = None\n",
    "\n",
    "    def _calculate_likelihood(self, mean, var, x):\n",
    "        # Handles potential zero variances (smoothing)\n",
    "        eps = 1e-4 \n",
    "        coeff = 1.0 / math.sqrt(2.0 * math.pi * var + eps)\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * var + eps)))\n",
    "        return coeff * exponent\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize data structures\n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        self.priors = {} \n",
    "        self.feature_likelihoods = {}\n",
    "\n",
    "        # Calculate class priors (P(Y))\n",
    "        for c in self.classes:\n",
    "            self.priors[c] = (y == c).sum() / n_samples\n",
    "\n",
    "        # Calculate feature likelihoods (P(X|Y))\n",
    "        for c in self.classes:\n",
    "            self.feature_likelihoods[c] = {}\n",
    "            for i in range(n_features):\n",
    "                features = X[y == c][:, i]\n",
    "                mean = features.mean()\n",
    "                var = features.var()\n",
    "                self.feature_likelihoods[c][i] = (mean, var)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "        for x in X:\n",
    "            posteriors = []\n",
    "            # Calculate posterior probabilities for each class\n",
    "            for c in self.classes:\n",
    "                prior = self.priors[c]\n",
    "                likelihood = 1.0\n",
    "                for i, feature in enumerate(x):\n",
    "                    likelihood *= self._calculate_likelihood(\n",
    "                        self.feature_likelihoods[c][i][0], \n",
    "                        self.feature_likelihoods[c][i][1], \n",
    "                        feature\n",
    "                    )\n",
    "                posterior = prior * likelihood\n",
    "                posteriors.append(posterior)\n",
    "            # Select class with highest posterior probability\n",
    "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3122f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201ea32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example if you have a categorical feature:\n",
    "categorical_feature_index = 2  # Index of the categorical column\n",
    "encoder = LabelEncoder()\n",
    "X[:, categorical_feature_index] = encoder.fit_transform(X[:, categorical_feature_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7944e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee182ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1-Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e23a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple, Dict, Any\n",
    "\n",
    "# Data Preprocessing\n",
    "def load_dataset() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    from sklearn.datasets import load_iris\n",
    "    data = load_iris()\n",
    "    X, y = data['data'], data['target']\n",
    "    return X, y\n",
    "\n",
    "def train_test_split(X: np.ndarray, y: np.ndarray, test_size: float = 0.2) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    indices = np.random.permutation(len(X))\n",
    "    test_set_size = int(len(X) * test_size)\n",
    "    test_indices = indices[:test_set_size]\n",
    "    train_indices = indices[test_set_size:]\n",
    "    return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "\n",
    "# Naive Bayes Implementation\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        self.class_prior = {}\n",
    "        self.mean_variance_by_class = {}\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.classes = np.unique(y)\n",
    "        for cls in self.classes:\n",
    "            X_cls = X[y == cls]\n",
    "            self.class_prior[cls] = len(X_cls) / len(X)\n",
    "            self.mean_variance_by_class[cls] = [(np.mean(feature), np.var(feature)) for feature in zip(*X_cls)]\n",
    "\n",
    "    def _calculate_likelihood(self, mean: float, var: float, x: float) -> float:\n",
    "        epsilon = 1e-4  # To prevent division by zero\n",
    "        coeff = 1.0 / np.sqrt(2.0 * np.pi * var + epsilon)\n",
    "        exponent = np.exp(-(np.square(x - mean) / (2 * var + epsilon)))\n",
    "        return coeff * exponent\n",
    "\n",
    "    def _calculate_posterior(self, X: np.ndarray) -> Dict:\n",
    "        posteriors = {}\n",
    "        for cls in self.classes:\n",
    "            prior = np.log(self.class_prior[cls])\n",
    "            conditional = np.sum([np.log(self._calculate_likelihood(mean, var, x)) for (mean, var), x in zip(self.mean_variance_by_class[cls], X)])\n",
    "            posteriors[cls] = prior + conditional\n",
    "        return posteriors\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        predictions = [max(self._calculate_posterior(x).items(), key=lambda x: x[1])[0] for x in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "# Evaluation Metrics\n",
    "def accuracy_score(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "def precision_recall_fscore(y_true: np.ndarray, y_pred: np.ndarray, average: str = 'macro') -> Tuple[float, float, float]:\n",
    "    unique_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
    "    precision, recall, fscore = 0, 0, 0\n",
    "\n",
    "    for cls in unique_classes:\n",
    "        tp = np.sum((y_pred == cls) & (y_true == cls))\n",
    "        fp = np.sum((y_pred == cls) & (y_true != cls))\n",
    "        fn = np.sum((y_pred != cls) & (y_true == cls))\n",
    "\n",
    "        precision_cls = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall_cls = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        fscore_cls = 2 * precision_cls * recall_cls / (precision_cls + recall_cls) if (precision_cls + recall_cls) > 0 else 0\n",
    "\n",
    "        precision += precision_cls\n",
    "        recall += recall_cls\n",
    "        fscore += fscore_cls\n",
    "\n",
    "    if average == 'macro':\n",
    "        precision /= len(unique_classes)\n",
    "        recall /= len(unique_classes)\n",
    "        fscore /= len(unique_classes)\n",
    "\n",
    "    return precision, recall, fscore\n",
    "\n",
    "# Main function to run the classifier\n",
    "def main():\n",
    "    X, y = load_dataset()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "    nb_classifier = NaiveBayesClassifier()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_pred = nb_classifier.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, fscore = precision_recall_fscore(y_test, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {fscore:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6772b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
