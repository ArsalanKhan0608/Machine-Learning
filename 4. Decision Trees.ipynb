{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85cf8336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [0 1 1 1]\n",
      "Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-e2dd14e9672b>:61: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  left_gini = 1.0 - sum([(np.sum(left_labels == c) / len(left_labels)) ** 2 for c in np.unique(labels)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, label=None, left=None, right=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.label = label\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class DecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_labels = np.unique(y)\n",
    "\n",
    "        # Stopping criteria\n",
    "        if len(unique_labels) == 1 or depth == self.max_depth:\n",
    "            leaf_label = self._majority_vote(y)\n",
    "            return DecisionTreeNode(label=leaf_label)\n",
    "\n",
    "        # Greedily select the best split according to Gini impurity\n",
    "        best_feature, best_threshold = self._best_split(X, y, num_samples, num_features)\n",
    "        \n",
    "        # Grow the children recursively\n",
    "        if best_feature is not None:\n",
    "            left_idx, right_idx = X[:, best_feature] < best_threshold, X[:, best_feature] >= best_threshold\n",
    "            left_child = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "            right_child = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "            return DecisionTreeNode(feature_index=best_feature, threshold=best_threshold, left=left_child, right=right_child)\n",
    "        \n",
    "        # If no split, return leaf node\n",
    "        leaf_label = self._majority_vote(y)\n",
    "        return DecisionTreeNode(label=leaf_label)\n",
    "\n",
    "    def _best_split(self, X, y, num_samples, num_features):\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_gini = 1.0  # Max possible value\n",
    "\n",
    "        for feature_index in range(num_features):\n",
    "            thresholds = np.unique(X[:, feature_index])\n",
    "            for threshold in thresholds:\n",
    "                gini = self._calculate_gini(X[:, feature_index], y, threshold)\n",
    "                if gini < best_gini:\n",
    "                    best_gini, best_feature, best_threshold = gini, feature_index, threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_gini(self, feature_column, labels, threshold):\n",
    "        # Split dataset\n",
    "        left_labels, right_labels = labels[feature_column < threshold], labels[feature_column >= threshold]\n",
    "        \n",
    "        # Calculate gini for children\n",
    "        left_gini = 1.0 - sum([(np.sum(left_labels == c) / len(left_labels)) ** 2 for c in np.unique(labels)])\n",
    "        right_gini = 1.0 - sum([(np.sum(right_labels == c) / len(right_labels)) ** 2 for c in np.unique(labels)])\n",
    "        \n",
    "        # Weighted gini\n",
    "        weighted_gini = len(left_labels) / len(labels) * left_gini + len(right_labels) / len(labels) * right_gini\n",
    "        return weighted_gini\n",
    "\n",
    "    def _majority_vote(self, labels):\n",
    "        majority_label = np.argmax(np.bincount(labels))\n",
    "        return majority_label\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = [self._predict(inputs, self.root) for inputs in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict(self, inputs, node):\n",
    "        if node.label is not None:\n",
    "            return node.label\n",
    "        if inputs[node.feature_index] < node.threshold:\n",
    "            return self._predict(inputs, node.left)\n",
    "        return self._predict(inputs, node.right)\n",
    "\n",
    "# Hypothetical Dataset\n",
    "data = pd.DataFrame({\n",
    "    'Age': [25, 40, 32, 50], \n",
    "    'Income': [50000, 80000, 65000, 120000],\n",
    "    'HasCreditCard': [1, 0, 1, 1],  # Converted to numeric for simplicity\n",
    "    'Purchased': [0, 1, 1, 1]  # Converted to numeric for simplicity\n",
    "})\n",
    "X = data.drop('Purchased', axis=1).values\n",
    "y = data['Purchased'].values\n",
    "\n",
    "# Instantiate and train the model\n",
    "model = DecisionTreeClassifier(max_depth=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "predictions = model.predict(X)\n",
    "print(\"Predictions:\", predictions)\n",
    "\n",
    "# Evaluation (for simplicity, using accuracy)\n",
    "accuracy = np.sum(predictions == y) / len(y)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611e42d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
