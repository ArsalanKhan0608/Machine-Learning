{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a932bddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, feature_index=None, threshold=None, \n",
    "                 left=None, right=None, value=None):\n",
    "        self.feature_index = feature_index  # Feature index for splitting\n",
    "        self.threshold = threshold          # Threshold for splitting\n",
    "        self.left = left                    # Left child node\n",
    "        self.right = right                  # Right child node\n",
    "        self.value = value                  # Prediction value if leaf node\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_leaf=1):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        if n_samples < self.min_samples_leaf or depth >= self.max_depth:\n",
    "            return Node(value=np.mean(y))  # Create leaf with average target\n",
    "\n",
    "        best_split = self._find_best_split(X, y)\n",
    "\n",
    "        if best_split is None:  # No informative split found\n",
    "            return Node(value=np.mean(y))\n",
    "\n",
    "        left_idx, right_idx = self._split_data(X, best_split)\n",
    "        left_child = self._build_tree(X[left_idx], y[left_idx], depth + 1)\n",
    "        right_child = self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
    "        return Node(**best_split, left=left_child, right=right_child)\n",
    "\n",
    "    def _find_best_split(self, X, y):\n",
    "        # (Implementation using variance reduction; placeholder for brevity)\n",
    "        pass \n",
    "\n",
    "    def _split_data(self, X, split):\n",
    "        # (Implementation to split data based on split['feature_index'] and split['threshold'])\n",
    "        pass \n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        for i, x in enumerate(X):\n",
    "            node = self.root\n",
    "            while node.value is None:  # Traverse until leaf node\n",
    "                if x[node.feature_index] <= node.threshold:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "            predictions[i] = node.value\n",
    "        return predictions\n",
    "\n",
    "class GBM:\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3, min_samples_leaf=1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        residuals = y.copy()\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_leaf=self.min_samples_leaf)\n",
    "            tree.fit(X, residuals)\n",
    "            self.trees.append(tree)\n",
    "            residuals -= self.learning_rate * tree.predict(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.zeros_like(X[:, 0])\n",
    "        for tree in self.trees:\n",
    "            predictions += self.learning_rate * tree.predict(X)\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36217cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.3104482346395718\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "boston = fetch_california_housing()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create and fit the GBM model\n",
    "model = GBM(n_estimators=50, learning_rate=0.1, max_depth=3, min_samples_leaf=5)  \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5f625d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-c33f28c6939f>:48: RuntimeWarning: invalid value encountered in log\n",
      "  tree.alpha = 0.5 * np.log((1.0 - min_error) / (min_error + 1e-10))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.threshold = None\n",
    "        self.feature_index = None\n",
    "        self.alpha = None\n",
    "        self.polarity = 1\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X_column = X[:, self.feature_index]\n",
    "        predictions = np.ones(n_samples)\n",
    "        if self.polarity == 1:\n",
    "            predictions[X_column < self.threshold] = -1\n",
    "        else:\n",
    "            predictions[X_column > self.threshold] = -1\n",
    "        return predictions\n",
    "def exponential_loss(y_true, y_pred):\n",
    "    return np.exp(-y_true * y_pred)\n",
    "class GBM:\n",
    "    def __init__(self, n_estimators=5, learning_rate=1.0):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        y_pred = np.zeros(np.shape(y))\n",
    "        for _ in range(self.n_estimators):\n",
    "            tree = DecisionStump()\n",
    "            min_error = float('inf')\n",
    "            for feature_i in range(X.shape[1]):\n",
    "                X_column = X[:, feature_i]\n",
    "                thresholds = np.unique(X_column)\n",
    "                for threshold in thresholds:\n",
    "                    p = 1\n",
    "                    prediction = np.ones(np.shape(y))\n",
    "                    prediction[X_column < threshold] = -1\n",
    "                    error = sum(exponential_loss(y, prediction))\n",
    "                    if error > 0.5:\n",
    "                        error = 1 - error\n",
    "                        p = -1\n",
    "                    if error < min_error:\n",
    "                        tree.polarity = p\n",
    "                        tree.threshold = threshold\n",
    "                        tree.feature_index = feature_i\n",
    "                        min_error = error\n",
    "            tree.alpha = 0.5 * np.log((1.0 - min_error) / (min_error + 1e-10))\n",
    "            y_pred += tree.alpha * tree.predict(X)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = np.array([tree.alpha * tree.predict(X) for tree in self.trees])\n",
    "        y_pred = np.sum(y_pred, axis=0)\n",
    "        y_pred = np.sign(y_pred)\n",
    "        return y_pred\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def preprocess_data():\n",
    "    data = load_iris()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    y = np.where(y == 0, -1, 1)  # Convert to binary\n",
    "\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = preprocess_data()\n",
    "gbm = GBM(n_estimators=10, learning_rate=0.5)\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(f'Accuracy: {accuracy(y_test, y_pred)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69207908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
